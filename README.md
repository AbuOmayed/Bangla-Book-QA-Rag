# ğŸ“˜ Bangla Book QA RAG

**Bangla Book QA RAG** is a bilingual Retrieval-Augmented Generation (RAG) system for answering questions from the *HSC26 Bangla 1st Paper textbook* in **Bangla** and **English**. This tool supports both CLI-based and web-based (Streamlit) interfaces, using **Ollama LLMs** for response generation and **LangChain** for pipeline orchestration.

---
## ğŸš€ Features

- âœ… Accepts questions in **Bangla** and **English**
- ğŸ“„ Parses and indexes Bangla textbook PDF
- ğŸ§  Retrieves relevant document chunks from vector store
- ğŸ’¬ Answers questions using **LLMs via Ollama** (deepseek-r1:14b)
- ğŸ–¥ï¸ Offers both a **CLI** version and a **Streamlit web app**
- ğŸ’¾ Supports **in-memory** and **AstraDB** vector storage
- ğŸ” Efficient document retrieval using **LangChain**
- ğŸ§¬ Embedding using **DeepSeek and llama2**
---

## ğŸ—ï¸ Architecture Overview

<p align="center">
  <img src="https://github.com/user-attachments/assets/2a50bd7b-3e07-4171-9ee6-63fd7373215d" width="600">
</p>

---

## ğŸ–¥ï¸ App Interfaces

<p align="center">
  <img src="" width="600">
</p>

---

## ğŸ§ª Sample Queries

| Question | Answer |
|---------|--------|
| à¦¬à¦¿à§Ÿà§‡à¦° à¦¸à¦®à§Ÿ à¦•à¦²à§à¦¯à¦¾à¦£à§€à¦° à¦ªà§à¦°à¦•à§ƒà¦¤ à¦¬à§Ÿà¦¸ à¦•à¦¤ à¦›à¦¿à¦²? | à§§à§« à¦¬à¦›à¦° |
| à¦†à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦·à¦¾à§Ÿ à¦¸à§à¦ªà§à¦°à§à¦· à¦•à¦¾à¦•à§‡ à¦¬à¦²à§‡? | à¦¶à¦®à§à¦­à§à¦¨à¦¾à¦¥ |
| à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à§Ÿà§‡à¦›à§‡? | à¦®à¦¾à¦®à¦¾ |

---

### ğŸ“· Screenshots

<p align="center">
  <img src="https://github.com/user-attachments/assets/9136efa6-87a2-4c8f-b7b7-7b2aedf219c5" width="600">
</p>
<p align="center">
  <img src="https://github.com/user-attachments/assets/97806550-71f5-486a-8408-080076ef46e9" width="600">
</p>
<p align="center">
  <img src="https://github.com/user-attachments/assets/a7ecb26a-a6e1-4a6c-841c-4d029bec4277" width="600">
</p>

---
## ğŸ› ï¸ Tools, Libraries & Packages

- **LangChain** â€“ Retrieval & QA orchestration
- **Ollama LLMs** â€“ (`deepseek-r1:14b`, `llama2`)
- **Streamlit** â€“ Web-based UI
- **PDFPlumber** â€“ Bangla-friendly PDF text extraction
- **AstraDB (Cassandra)** â€“ Vector DB for persistent storage
- **RecursiveCharacterTextSplitter** â€“ Smart chunking for context-aware retrieval

---

## ğŸ“¡ API Documentation (Not Implemented)

- Currently CLI and GUI only.
- API (FastAPI or Flask) can be integrated for production use.

---

## ğŸ“Š Evaluation Matrix (Planned/Future Work)

| Metric | Value | Notes |
|--------|-------|-------|
| Top-1 Accuracy | -- | Manual testing with known questions |
| Response Time | -- | On local CPU (LLM performance varies) |
| BLEU/ROUGE | -- | Planned for future implementation |

---

## â“Question Answer Section

### ğŸ“„ What method or library did you use to extract the text, and why?

- **Library**: `PDFPlumberLoader` (via LangChain)
- **Reason**: PDFPlumber preserves **Bangla Unicode** and handles line breaks and ligatures better than PyPDF2 or pdfminer.
- **Challenge**: Some PDF pages had irregular formatting (broken words, missing punctuation), requiring chunking with tolerance for broken structure.

### âœ‚ï¸ What chunking strategy did you choose?

- **Method**: `RecursiveCharacterTextSplitter`
- **Config**: `chunk_size=1000`, `chunk_overlap=300`
- **Why**: This strategy balances coherence and retrieval relevance. It avoids splitting in mid-sentence/word, helping embeddings maintain semantic continuity.

### ğŸ§¬ What embedding model did you use?

- **Model**: `OllamaEmbeddings(model="deepseek-r1:14b")`
- **Why**: It's multilingual and effective in capturing contextual meaning in Bangla and English.
- **Advantage**: Fine-grained semantic understanding that outperforms basic word vectors (e.g., TF-IDF).

### ğŸ§  How are you comparing the query with your stored chunks?

- **Method**: `vector_store.similarity_search(query=question)`
- **Similarity**: Cosine distance (via FAISS or AstraDB backend)
- **Why**: Vector similarity ensures semantically close chunks, even if they donâ€™t share surface-level words.

### ğŸ§ How do you ensure meaningful comparison between question and document chunks?

- Chunks are semantically rich (1000 chars) and overlapping (300 chars), ensuring broader context.
- Queries are passed to embedding model to generate query vectors before comparison.
- If the query is vague or missing context, fallback is:
  - Either generic answers (e.g., â€œI don't knowâ€)
  - Or retrieving the most relevant-looking chunk regardless of full match.

### âœ… Do the results seem relevant?

- **Yes**, for clear, factual, and Bangla-language textbook queries.
- **Improvements possible**:
  - Add metadata-based filtering (e.g., chapter tags)
  - Use sentence-level chunking for finer granularity
  - Explore OpenAI or Cohere embeddings for richer semantic capture
  - Add query rewriting for vague or incomplete questions

---

## ğŸ“ Repository Structure

```
ğŸ“¦ bangla-book-qa-rag
 â”£ ğŸ“„ README.md
 â”£ ğŸ“„ requirements.txt
 â”£ ğŸ“„ BanglaPDF_QA_Apps.py         # Streamlit Web App
 â”£ ğŸ“„ BanglaPDF_QA (main).py       # CLI App with local store
 â”£ ğŸ“„ BangalPDF_QA_AstraDB.py      # CLI App with AstraDB
 â”£ ğŸ“ pdfstore/                    # Uploaded PDFs for app
```
## âš™ï¸ Setup Instructions

```bash
# Clone the repository
git clone https://github.com/yourusername/bangla-book-qa-rag.git
cd bangla-book-qa-rag

# Set up virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install required packages
pip install -r requirements.txt

# Run the Streamlit app
streamlit run BanglaPDF_QA_Apps.py

# OR run CLI version with local vector store
python BanglaPDF_QA\ \(main\).py

# OR run CLI version with AstraDB
python BangalPDF_QA_AstraDB.py
```

## ğŸ¤ Credits

Created by **Abu Omayed**
